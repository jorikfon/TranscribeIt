import Foundation
import WhisperKit
import Metal

/// –°–µ—Ä–≤–∏—Å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ WhisperKit —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Metal GPU –∏ Neural Engine
///
/// –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç on-device —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∞—É–¥–∏–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Whisper
/// –¥–ª—è Apple Silicon. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –∞—É–¥–∏–æ, –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
/// –∏ vocabulary corrections –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.
///
/// ## –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏
/// - `tiny` - –°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è, –±–∞–∑–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (~39M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
/// - `base` - –ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ (~74M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
/// - `small` - –•–æ—Ä–æ—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (~244M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è
/// - `medium` - –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (~769M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
/// - `large` - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (~1550M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
///
/// ## –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
/// - **Metal GPU**: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º
/// - **Neural Engine**: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è encoder/decoder/prefill
/// - **Unified Memory**: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ Apple Silicon
/// - **Prewarm**: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
///
/// ## –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
/// - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∏—Ö–æ–≥–æ –∞—É–¥–∏–æ
/// - –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞
/// - Vocabulary corrections —á–µ—Ä–µ–∑ VocabularyManager
/// - Performance metrics (RTF - Real-Time Factor)
/// - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —è–∑—ã–∫–æ–≤
/// - –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
///
/// ## Example
/// ```swift
/// let whisperService = WhisperService(
///     modelSize: "small",
///     vocabularyManager: VocabularyManager.shared
/// )
///
/// // –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
/// try await whisperService.loadModel()
///
/// // –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ
/// let audioSamples: [Float] = // ... 16kHz mono audio
/// let text = try await whisperService.transcribe(
///     audioSamples: audioSamples,
///     contextPrompt: "Previous dialogue context"
/// )
/// print("Transcribed: \(text)")
/// print("RTF: \(whisperService.averageRTF)")
/// ```
///
/// ## Performance
/// –¢–∏–ø–∏—á–Ω—ã–π Real-Time Factor (RTF) –Ω–∞ Apple Silicon:
/// - M1/M2/M3 + tiny: 0.05-0.1x (20x –±—ã—Å—Ç—Ä–µ–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏)
/// - M1/M2/M3 + small: 0.15-0.3x (3-7x –±—ã—Å—Ç—Ä–µ–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏)
/// - M1/M2/M3 + medium: 0.4-0.8x (1.2-2.5x –±—ã—Å—Ç—Ä–µ–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏)
///
/// ## Thread Safety
/// WhisperService –Ω–µ —è–≤–ª—è–µ—Ç—Å—è thread-safe. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–¥–∏–Ω —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –æ—á–µ—Ä–µ–¥—å
/// –∏–ª–∏ –∑–∞—â–∏—â–∞–π—Ç–µ –¥–æ—Å—Ç—É–ø —á–µ—Ä–µ–∑ actor/locks.
public class WhisperService {
    private var whisperKit: WhisperKit?
    private var modelSize: String  // –ò–∑–º–µ–Ω–µ–Ω–æ —Å let –Ω–∞ var –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–º–µ–Ω—ã –º–æ–¥–µ–ª–∏
    private let vocabularyManager: VocabularyManagerProtocol
    private let audioNormalizer = AudioNormalizer(parameters: .default)

    // Prompt –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    public var promptText: String? = nil

    // –í–∫–ª—é—á–∏—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –∞—É–¥–∏–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–∫–ª—é—á–µ–Ω–æ)
    public var enableNormalization: Bool = true

    // Performance metrics
    public private(set) var lastTranscriptionTime: TimeInterval = 0
    public private(set) var averageRTF: Double = 0  // Real-Time Factor
    private var transcriptionCount: Int = 0
    private var totalRTF: Double = 0

    // GPU/Neural Engine status
    public private(set) var isMetalAvailable: Bool = false
    public private(set) var isNeuralEngineAvailable: Bool = false
    public private(set) var gpuName: String = "Unknown"

    /// –†–∞–∑–º–µ—Ä —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏
    public var currentModelSize: String {
        return modelSize
    }

    public init(
        modelSize: String,
        vocabularyManager: VocabularyManagerProtocol
    ) {
        self.modelSize = modelSize
        self.vocabularyManager = vocabularyManager
        LogManager.transcription.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WhisperService —Å –º–æ–¥–µ–ª—å—é \(modelSize)")
    }

    /// –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç WhisperKit —Å –Ω–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
    ///
    /// –û—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å –∏–∑ –ø–∞–º—è—Ç–∏ –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–æ–≤—É—é. –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è
    /// –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ –≤–æ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å small –Ω–∞ medium –¥–ª—è –ª—É—á—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏).
    ///
    /// - Parameter newModelSize: –†–∞–∑–º–µ—Ä –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (tiny, base, small, medium, large)
    /// - Throws: `WhisperError.modelLoadFailed` –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å
    ///
    /// ## Example
    /// ```swift
    /// // –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –±–æ–ª–µ–µ —Ç–æ—á–Ω—É—é –º–æ–¥–µ–ª—å
    /// try await whisperService.reloadModel(newModelSize: "medium")
    /// ```
    ///
    /// - Note: –ï—Å–ª–∏ –º–æ–¥–µ–ª—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –º–µ—Ç–æ–¥ –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ—Ç
    /// - Note: –ü–æ—Å–ª–µ —Å–º–µ–Ω—ã –º–æ–¥–µ–ª–∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    public func reloadModel(newModelSize: String) async throws {
        guard newModelSize != modelSize else {
            LogManager.transcription.info("–ú–æ–¥–µ–ª—å \(newModelSize) —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
            return
        }

        LogManager.transcription.begin("–°–º–µ–Ω–∞ –º–æ–¥–µ–ª–∏", details: "\(modelSize) ‚Üí \(newModelSize)")

        // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Å—Ç–∞—Ä—É—é –º–æ–¥–µ–ª—å
        whisperKit = nil

        // –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä
        modelSize = newModelSize

        // –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å
        try await loadModel()

        // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        resetPerformanceStats()

        LogManager.transcription.success("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–º–µ–Ω–µ–Ω–∞ –Ω–∞ \(newModelSize)")
    }

    /// –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å Whisper —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è Apple Silicon
    ///
    /// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç WhisperKit —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é, –∏—Å–ø–æ–ª—å–∑—É—è Neural Engine –∏ Metal GPU
    /// –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏–∑ Hugging Face –∏ –∫—ç—à–∏—Ä—É—é—Ç—Å—è
    /// –ª–æ–∫–∞–ª—å–Ω–æ –≤ `~/Library/Application Support/TranscribeIt/Models/`.
    ///
    /// - Throws: `WhisperError.modelLoadFailed` –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å
    ///
    /// ## Compute Options
    /// - Mel —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞: CPU + GPU
    /// - Audio encoder: CPU + Neural Engine
    /// - Text decoder: CPU + Neural Engine
    /// - Prefill: CPU + Neural Engine
    ///
    /// ## Example
    /// ```swift
    /// let service = WhisperService(modelSize: "small", vocabularyManager: VocabularyManager.shared)
    /// try await service.loadModel()
    /// // –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
    /// ```
    ///
    /// - Note: –ü–µ—Ä–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∑–∞–Ω–∏–º–∞–µ—Ç –≤—Ä–µ–º—è (—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å Hugging Face)
    /// - Note: –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–∞–ø—É—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –±—ã—Å—Ç—Ä–µ–µ
    public func loadModel() async throws {
        LogManager.transcription.begin("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏", details: modelSize)

        // –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –ø—É—Ç—å –¥–ª—è –∫—ç—à–∞ –º–æ–¥–µ–ª–µ–π
        // –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ –º–µ–∂–¥—É –∑–∞–ø—É—Å–∫–∞–º–∏
        let modelsPath = FileManager.default.homeDirectoryForCurrentUser
            .appendingPathComponent("Library/Application Support/TranscribeIt/Models")

        // –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        try? FileManager.default.createDirectory(at: modelsPath, withIntermediateDirectories: true)

        LogManager.transcription.info("–ü—É—Ç—å –∫ –º–æ–¥–µ–ª—è–º: \(modelsPath.path)")

        // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —é–Ω–∏—Ç–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ M1 MAX
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º Neural Engine –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ
        let computeOptions = ModelComputeOptions(
            melCompute: .cpuAndGPU,              // Mel —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞ - GPU
            audioEncoderCompute: .cpuAndNeuralEngine,  // Audio encoder - Neural Engine
            textDecoderCompute: .cpuAndNeuralEngine,   // Text decoder - Neural Engine
            prefillCompute: .cpuAndNeuralEngine        // Prefill - Neural Engine
        )

        do {
            // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WhisperKit —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é –∏ –ø—É—Ç—ë–º –∫ –∫—ç—à—É
            // –ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å Hugging Face –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ
            whisperKit = try await WhisperKit(
                model: modelSize,
                downloadBase: modelsPath,  // –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –ø—É—Ç—å
                modelRepo: "argmaxinc/whisperkit-coreml",
                computeOptions: computeOptions,
                verbose: true,
                logLevel: .debug,
                prewarm: true  // –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
            )

            LogManager.transcription.success("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞", details: modelSize)

            // –ü—Ä–æ–≤–µ—Ä–∫–∞ Metal acceleration –∏ Neural Engine
            verifyMetalAcceleration()
        } catch {
            LogManager.transcription.failure("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏", error: error)
            throw WhisperError.modelLoadFailed(underlying: error, modelSize: modelSize)
        }
    }

    /// –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Metal GPU acceleration –∏ Neural Engine
    private func verifyMetalAcceleration() {
        guard let device = MTLCreateSystemDefaultDevice() else {
            LogManager.transcription.error("Metal GPU –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
            isMetalAvailable = false
            isNeuralEngineAvailable = false
            gpuName = "None"
            return
        }

        // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—É—Å GPU
        isMetalAvailable = true
        gpuName = device.name
        isNeuralEngineAvailable = device.supportsFamily(.apple7) // M1 –∏ –Ω–æ–≤–µ–µ

        let memoryGB = device.recommendedMaxWorkingSetSize / 1024 / 1024 / 1024
        let isAppleSilicon = device.supportsFamily(.apple7)
        let maxThreads = device.maxThreadsPerThreadgroup

        LogManager.transcription.info("üöÄ Apple Silicon Acceleration")
        LogManager.transcription.info("  GPU: \(device.name)")
        LogManager.transcription.info("  Unified Memory: \(memoryGB)GB")
        LogManager.transcription.info("  Metal: \(isAppleSilicon ? "‚úÖ" : "‚ùå") Apple Silicon")
        LogManager.transcription.info("  Neural Engine: \(isNeuralEngineAvailable ? "‚úÖ Enabled (All components)" : "‚ùå")")
        LogManager.transcription.info("  Compute Units: Mel=GPU, Encoder/Decoder/Prefill=ANE")
        LogManager.transcription.debug("  Max threads: \(maxThreads.width)√ó\(maxThreads.height)√ó\(maxThreads.depth)")

        if device.name.contains("M1") {
            LogManager.transcription.info("  üî• M1 detected - using all performance cores + Neural Engine")
        } else if device.name.contains("M2") || device.name.contains("M3") {
            LogManager.transcription.info("  üî• \(device.name) detected - maximum performance mode")
        }
    }

    /// –ë—ã—Å—Ç—Ä–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ —á–∞–Ω–∫–∞ –¥–ª—è real-time –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    ///
    /// –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏: greedy decoding (topK=1),
    /// –±–µ–∑ beam search, –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥. –ü—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π
    /// —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤–æ –≤—Ä–µ–º—è –∑–∞–ø–∏—Å–∏ –∏–ª–∏ –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.
    ///
    /// - Parameter audioSamples: –ú–∞—Å—Å–∏–≤ Float32 –∞—É–¥–∏–æ —Å—ç–º–ø–ª–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ 16kHz mono
    /// - Returns: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º vocabulary corrections
    /// - Throws: `WhisperError.modelNotLoaded` –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
    ///
    /// ## Example
    /// ```swift
    /// // –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —á–∞–Ω–∫–∞ –∞—É–¥–∏–æ
    /// let chunk: [Float] = // ... 3 —Å–µ–∫—É–Ω–¥—ã –∞—É–¥–∏–æ (48000 samples @ 16kHz)
    /// let quickResult = try await whisperService.transcribeChunk(audioSamples: chunk)
    /// print("Quick transcription: \(quickResult)")
    /// ```
    ///
    /// - Note: –î–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `transcribe(audioSamples:contextPrompt:)`
    /// - Note: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Ç–∏—Ö–æ–≥–æ –∞—É–¥–∏–æ
    public func transcribeChunk(audioSamples: [Float]) async throws -> String {
        guard let whisperKit = whisperKit else {
            throw WhisperError.modelNotLoaded
        }

        // –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –ø–µ—Ä–µ–¥ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π
        var processedSamples = audioSamples
        if enableNormalization {
            let stats = audioNormalizer.analyze(audioSamples)
            if stats.isQuiet {
                LogManager.transcription.info("–¢–∏—Ö–æ–µ –∞—É–¥–∏–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ (RMS=\(stats.rms)), –ø—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é")
                processedSamples = audioNormalizer.normalize(audioSamples)
            }
        }

        // –î–ª—è real-time –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º Quality Enhancement (—Å–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–æ)
        // –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        let settings = UserSettings.shared
        let prefillPrompt = settings.buildFullPrefillPrompt()
        let usePrefill = !prefillPrompt.isEmpty

        let options = DecodingOptions(
            task: .transcribe,        // TRANSCRIBE, –Ω–µ translate!
            language: settings.transcriptionLanguage,  // –Ø–∑—ã–∫ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
            temperature: 0.0,         // –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥
            topK: 1,                  // Greedy decoding –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ (–ù–ï beam search –≤ real-time)
            usePrefillPrompt: usePrefill,   // –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Å–ª–æ–≤–∞—Ä–µ–π –µ—Å–ª–∏ –µ—Å—Ç—å
            usePrefillCache: usePrefill,    // –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            detectLanguage: false     // –û—Ç–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —è–∑—ã–∫ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        )

        let results = try await whisperKit.transcribe(
            audioArray: processedSamples,
            decodeOptions: options
        )

        guard let firstResult = results.first else {
            return ""
        }

        let transcription = firstResult.text.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)

        // Apply vocabulary corrections
        let correctedText = vocabularyManager.correctTranscription(transcription)

        return correctedText
    }

    /// –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
    ///
    /// –í—ã–ø–æ–ª–Ω—è–µ—Ç –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º beam search –∏ quality enhancement.
    /// –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏
    /// –¥–∏–∞–ª–æ–≥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–µ—Ä–µ–¥–∞–≤–∞—è —Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–µ–ø–ª–∏–∫ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–º–µ–Ω –∏ —Ç–µ—Ä–º–∏–Ω–æ–≤).
    ///
    /// - Parameters:
    ///   - audioSamples: –ú–∞—Å—Å–∏–≤ Float32 –∞—É–¥–∏–æ —Å—ç–º–ø–ª–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ 16kHz mono
    ///   - contextPrompt: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (–º–∞–∫—Å 224 —Ç–æ–∫–µ–Ω–∞)
    /// - Returns: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º vocabulary corrections
    /// - Throws: `WhisperError.modelNotLoaded` –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
    ///
    /// ## Example
    /// ```swift
    /// // –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞
    /// let previousContext = "–ò–≤–∞–Ω: –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ. –ú–∞—Ä–∏—è: –î–æ–±—Ä—ã–π –¥–µ–Ω—å, –ò–≤–∞–Ω."
    /// let audioSamples: [Float] = // ... –∞—É–¥–∏–æ —Å–ª–µ–¥—É—é—â–µ–π —Ä–µ–ø–ª–∏–∫–∏
    /// let text = try await whisperService.transcribe(
    ///     audioSamples: audioSamples,
    ///     contextPrompt: previousContext
    /// )
    /// ```
    ///
    /// ## Performance
    /// - –í–∫–ª—é—á–∞–µ—Ç quality enhancement –¥–ª—è –ª—É—á—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
    /// - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç beam search (—Ç–æ–ø-5 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤)
    /// - –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø—Ä–µ—Ñ–∏–ª—å–Ω—ã–π –∫—ç—à –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤
    /// - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∏—Ö–æ–≥–æ –∞—É–¥–∏–æ
    ///
    /// - Note: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–º–µ–Ω—è–µ—Ç `promptText` –Ω–∞ –≤—Ä–µ–º—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    /// - Note: –ü–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (RTF)
    public func transcribe(audioSamples: [Float], contextPrompt: String? = nil) async throws -> String {
        // –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω
        var promptTokens: [Int]? = nil
        if let context = contextPrompt, !context.isEmpty {
            if let tokenizer = whisperKit?.tokenizer {
                promptTokens = tokenizer.encode(text: context)
                LogManager.transcription.debug("–¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç: \(promptTokens?.count ?? 0) —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ \(context.count) —Å–∏–º–≤–æ–ª–æ–≤: \"\(context.prefix(100))...\"")
            } else {
                LogManager.transcription.warning("Tokenizer –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –±—É–¥–µ—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω")
            }
        }

        // –í—ã–∑—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Å —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
        let result = try await transcribeInternal(audioSamples: audioSamples, promptTokens: promptTokens)

        return result
    }

    /// –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö —Å –∏–∑–º–µ—Ä–µ–Ω–∏–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥)
    /// - Parameters:
    ///   - audioSamples: –ú–∞—Å—Å–∏–≤ Float32 –∞—É–¥–∏–æ —Å—ç–º–ø–ª–æ–≤ (16kHz mono)
    ///   - promptTokens: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –º–∞—Å—Å–∏–≤ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
    /// - Returns: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    private func transcribeInternal(audioSamples: [Float], promptTokens: [Int]? = nil) async throws -> String {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–º–µ–Ω—É –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        try Task.checkCancellation()

        guard let whisperKit = whisperKit else {
            LogManager.transcription.failure("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è", message: "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            throw WhisperError.modelNotLoaded
        }

        let sampleCount = audioSamples.count
        let audioDuration = Double(sampleCount) / 16000.0  // 16kHz sample rate

        LogManager.transcription.begin("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è", details: "\(sampleCount) samples, \(String(format: "%.2f", audioDuration))s")

        // –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –ø–µ—Ä–µ–¥ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π
        var processedSamples = audioSamples
        if enableNormalization {
            let stats = audioNormalizer.analyze(audioSamples)
            LogManager.transcription.debug("–ê—É–¥–∏–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: peak=\(String(format: "%.3f", stats.peak)), rms=\(String(format: "%.3f", stats.rms))")

            if stats.isQuiet {
                LogManager.transcription.info("–¢–∏—Ö–æ–µ –∞—É–¥–∏–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ (RMS=\(String(format: "%.3f", stats.rms))), –ø—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é")
                processedSamples = audioNormalizer.normalize(audioSamples)

                let normalizedStats = audioNormalizer.analyze(processedSamples)
                LogManager.transcription.success("–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: RMS \(String(format: "%.3f", stats.rms)) ‚Üí \(String(format: "%.3f", normalizedStats.rms))")
            } else {
                LogManager.transcription.debug("–ì—Ä–æ–º–∫–æ—Å—Ç—å –∞—É–¥–∏–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
            }
        }

        let startTime = Date()

        do {
            // –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –°–ú–ï–®–ê–ù–ù–û–ô —Ä–µ—á–∏ (RU+EN)
            // –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ–∂–∏–º –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
            let settings = UserSettings.shared
            let useQualityMode = settings.useQualityEnhancement

            // –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ—Ñ–∏–ª–ª –ø—Ä–æ–º–ø—Ç –∏–∑ —Å–ª–æ–≤–∞—Ä–µ–π –∏ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            let prefillPrompt = settings.buildFullPrefillPrompt()
            let usePrefill = !prefillPrompt.isEmpty

            let options = DecodingOptions(
                task: .transcribe,      // transcribe (–Ω–µ translate!)
                language: settings.transcriptionLanguage,  // –Ø–∑—ã–∫ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "ru")
                temperature: 0.0,       // –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥
                temperatureIncrementOnFallback: useQualityMode && settings.useTemperatureFallback ? 0.2 : 0.0,
                temperatureFallbackCount: useQualityMode && settings.useTemperatureFallback ? 5 : 0,
                topK: useQualityMode ? 5 : 1,  // Beam search: 5 beams vs greedy (1)
                usePrefillPrompt: usePrefill,   // –ò—Å–ø–æ–ª—å–∑—É–µ–º prefill –µ—Å–ª–∏ –µ—Å—Ç—å —Å–ª–æ–≤–∞—Ä–∏/–ø—Ä–æ–º–ø—Ç
                usePrefillCache: usePrefill,    // –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ prefill
                detectLanguage: false,          // –û—Ç–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —è–∑—ã–∫ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
                promptTokens: promptTokens,     // –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤ –≤–∏–¥–µ —Ç–æ–∫–µ–Ω–æ–≤
                compressionRatioThreshold: useQualityMode ? settings.compressionRatioThreshold : nil,
                logProbThreshold: useQualityMode ? settings.logProbThreshold : nil,
                noSpeechThreshold: useQualityMode ? 0.6 : nil  // –§–∏–ª—å—Ç—Ä —Ç–∏—à–∏–Ω—ã
            )

            // –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫
            LogManager.transcription.info("üåê Language: \(settings.transcriptionLanguage)")
            if let tokens = promptTokens, !tokens.isEmpty {
                LogManager.transcription.info("üí¨ Context prompt tokens: \(tokens.count)")
            }
            if !settings.selectedDictionaryIds.isEmpty {
                LogManager.transcription.info("üìö Active dictionaries: \(settings.selectedDictionaryIds.joined(separator: ", "))")
            }
            if !settings.customPrefillPrompt.isEmpty {
                LogManager.transcription.info("‚úèÔ∏è  Custom prefill: \(settings.customPrefillPrompt.prefix(50))...")
            }

            if useQualityMode {
                LogManager.transcription.info("‚ú® Quality Enhancement Mode:")
                LogManager.transcription.info("  - Beam search: \(options.topK) beams")
                if settings.useTemperatureFallback {
                    LogManager.transcription.info("  - Temperature fallback: 0.0 ‚Üí 1.0 (5 steps)")
                }
                LogManager.transcription.info("  - Compression ratio filter: \(settings.compressionRatioThreshold ?? 0.0)")
                LogManager.transcription.info("  - Log prob filter: \(settings.logProbThreshold ?? 0.0)")
            }

            // TODO: –î–æ–±–∞–≤–∏—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é –ø—Ä–æ–º–ø—Ç–∞ –∫–æ–≥–¥–∞ –ø–æ–ª—É—á–∏–º –¥–æ—Å—Ç—É–ø –∫ tokenizer
            if usePrefill {
                LogManager.transcription.debug("Prefill prompt (\(prefillPrompt.count) chars): \"\(prefillPrompt.prefix(100))...\"")
            }
            if let prompt = promptText, !prompt.isEmpty {
                LogManager.transcription.debug("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç: \"\(prompt.prefix(50))...\"")
            }

            let results = try await whisperKit.transcribe(
                audioArray: processedSamples,
                decodeOptions: options
            )

            // –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            let transcriptionTime = Date().timeIntervalSince(startTime)
            lastTranscriptionTime = transcriptionTime

            // –í—ã—á–∏—Å–ª—è–µ–º Real-Time Factor (RTF)
            // RTF = transcription_time / audio_duration
            // RTF < 1.0 = faster than real-time
            // RTF > 1.0 = slower than real-time
            let rtf = transcriptionTime / audioDuration
            transcriptionCount += 1
            totalRTF += rtf
            averageRTF = totalRTF / Double(transcriptionCount)

            // –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ –º–∞—Å—Å–∏–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            guard let firstResult = results.first else {
                LogManager.transcription.failure("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è", message: "–ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                return ""
            }

            let transcription = firstResult.text
            let cleanedText = transcription.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)

            // Apply vocabulary corrections
            let correctedText = vocabularyManager.correctTranscription(cleanedText)

            // –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            let speedMultiplier = audioDuration / transcriptionTime
            LogManager.transcription.success(
                "–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞",
                details: "\"\(correctedText)\" (\(String(format: "%.2f", transcriptionTime))s, RTF: \(String(format: "%.2f", rtf))x, \(String(format: "%.1f", speedMultiplier))x realtime)"
            )
            LogManager.transcription.debug("Avg RTF: \(String(format: "%.2f", self.averageRTF))x over \(self.transcriptionCount) transcriptions")

            if cleanedText != correctedText {
                LogManager.transcription.debug("Vocabulary correction applied: '\(cleanedText)' -> '\(correctedText)'")
            }

            return correctedText
        } catch {
            let elapsedTime = Date().timeIntervalSince(startTime)
            LogManager.transcription.failure("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è", error: error)
            throw WhisperError.transcriptionFailed(underlying: error, duration: elapsedTime)
        }
    }

    /// –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    public func getPerformanceStats() -> PerformanceStats {
        return PerformanceStats(
            lastTranscriptionTime: lastTranscriptionTime,
            averageRTF: averageRTF,
            transcriptionCount: transcriptionCount,
            modelSize: modelSize
        )
    }

    /// –°–±—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    public func resetPerformanceStats() {
        lastTranscriptionTime = 0
        averageRTF = 0
        transcriptionCount = 0
        totalRTF = 0
        LogManager.transcription.info("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–±—Ä–æ—à–µ–Ω–∞")
    }

    /// –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
    public var isReady: Bool {
        return whisperKit != nil
    }

    deinit {
        LogManager.transcription.info("WhisperService –¥–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    }
}

// WhisperError –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –≤ Sources/Errors/WhisperError.swift

/// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
public struct PerformanceStats {
    public let lastTranscriptionTime: TimeInterval
    public let averageRTF: Double
    public let transcriptionCount: Int
    public let modelSize: String

    public var description: String {
        """
        Performance Statistics:
        - Model: \(modelSize)
        - Transcriptions: \(transcriptionCount)
        - Last Time: \(String(format: "%.2f", lastTranscriptionTime))s
        - Average RTF: \(String(format: "%.2f", averageRTF))x
        - Status: \(averageRTF < 1.0 ? "‚úì Faster than realtime" : "‚ö†Ô∏è Slower than realtime")
        """
    }
}
