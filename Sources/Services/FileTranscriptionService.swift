import Foundation
import AVFoundation
import TranscribeItCore

/// –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ –¥–∏–∫—Ç–æ—Ä–∞–º –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
public struct DialogueTranscription {
    public struct Turn: Identifiable {
        public let id = UUID()  // –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è SwiftUI
        public let speaker: Speaker
        public let text: String
        public let startTime: TimeInterval  // –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Ä–µ–ø–ª–∏–∫–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        public let endTime: TimeInterval    // –í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è —Ä–µ–ø–ª–∏–∫–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

        public enum Speaker {
            case left   // –õ–µ–≤—ã–π –∫–∞–Ω–∞–ª (Speaker 1)
            case right  // –ü—Ä–∞–≤—ã–π –∫–∞–Ω–∞–ª (Speaker 2)

            public var displayName: String {
                switch self {
                case .left: return "Speaker 1"
                case .right: return "Speaker 2"
                }
            }

            public var color: String {
                switch self {
                case .left: return "blue"
                case .right: return "orange"
                }
            }
        }

        public var duration: TimeInterval {
            return endTime - startTime
        }

        public init(speaker: Speaker, text: String, startTime: TimeInterval, endTime: TimeInterval) {
            self.speaker = speaker
            self.text = text
            self.startTime = startTime
            self.endTime = endTime
        }
    }

    public let turns: [Turn]
    public let isStereo: Bool
    public let totalDuration: TimeInterval  // –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–∏–∞–ª–æ–≥–∞

    public init(turns: [Turn], isStereo: Bool, totalDuration: TimeInterval = 0) {
        self.turns = turns
        self.isStereo = isStereo
        self.totalDuration = totalDuration
    }

    /// –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–ø–ª–∏–∫–∏, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–¥–ª—è timeline)
    public var sortedByTime: [Turn] {
        return turns.sorted { $0.startTime < $1.startTime }
    }

    /// –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∏–∞–ª–æ–≥ –∫–∞–∫ —Ç–µ–∫—Å—Ç —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
    public func formatted() -> String {
        if !isStereo || turns.isEmpty {
            return turns.first?.text ?? ""
        }

        return sortedByTime.map { turn in
            let timestamp = formatTimestamp(turn.startTime)
            return "[\(timestamp)] \(turn.speaker.displayName): \(turn.text)"
        }.joined(separator: "\n\n")
    }

    private func formatTimestamp(_ seconds: TimeInterval) -> String {
        let minutes = Int(seconds) / 60
        let secs = Int(seconds) % 60
        let millis = Int((seconds.truncatingRemainder(dividingBy: 1)) * 1000)
        return String(format: "%02d:%02d.%03d", minutes, secs, millis)
    }

    /// –£–±–∏—Ä–∞–µ—Ç –ø–µ—Ä–∏–æ–¥—ã —Ç–∏—à–∏–Ω—ã (–≥–¥–µ –æ–±–∞ —Å–ø–∏–∫–µ—Ä–∞ –º–æ–ª—á–∞—Ç) –∏ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    /// –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–µ–∂—É—Ç–æ–∫ —Ç–∏—à–∏–Ω—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è: 2 —Å–µ–∫—É–Ω–¥—ã
    public func removesilencePeriods(minGap: TimeInterval = 2.0) -> DialogueTranscription {
        guard !turns.isEmpty else { return self }

        // –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–ø–ª–∏–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        let sorted = sortedByTime

        var compressedTurns: [Turn] = []
        var currentTime: TimeInterval = 0

        for (index, turn) in sorted.enumerated() {
            let turnDuration = turn.endTime - turn.startTime

            if index == 0 {
                // –ü–µ—Ä–≤–∞—è —Ä–µ–ø–ª–∏–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 0
                compressedTurns.append(Turn(
                    speaker: turn.speaker,
                    text: turn.text,
                    startTime: currentTime,
                    endTime: currentTime + turnDuration
                ))
                currentTime += turnDuration
            } else {
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ–∫ —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Ä–µ–ø–ª–∏–∫–æ–π
                let previousTurn = sorted[index - 1]
                let gap = turn.startTime - previousTurn.endTime

                // –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—É–∑—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∞ –º–µ–Ω—å—à–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
                // –ò–Ω–∞—á–µ —ç—Ç–æ —Ç–∏—à–∏–Ω–∞, –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ —É–±—Ä–∞—Ç—å
                if gap < minGap {
                    currentTime += gap
                } else {
                    // –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –ø–∞—É–∑—É (0.5 —Å–µ–∫) –≤–º–µ—Å—Ç–æ –¥–ª–∏–Ω–Ω–æ–π —Ç–∏—à–∏–Ω—ã
                    currentTime += 0.5
                }

                compressedTurns.append(Turn(
                    speaker: turn.speaker,
                    text: turn.text,
                    startTime: currentTime,
                    endTime: currentTime + turnDuration
                ))
                currentTime += turnDuration
            }
        }

        // –ù–æ–≤–∞—è –æ–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å - —ç—Ç–æ –≤—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ä–µ–ø–ª–∏–∫–∏
        let newTotalDuration = compressedTurns.last?.endTime ?? 0

        LogManager.app.info("–°–∂–∞—Ç–∏–µ –¥–∏–∞–ª–æ–≥–∞: \(String(format: "%.1f", totalDuration))s -> \(String(format: "%.1f", newTotalDuration))s (\(turns.count) —Ä–µ–ø–ª–∏–∫)")

        return DialogueTranscription(
            turns: compressedTurns,
            isStereo: isStereo,
            totalDuration: newTotalDuration
        )
    }
}

/// Snapshot –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π
/// –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤ –Ω–∞—á–∞–ª–µ transcribeFile() —á—Ç–æ–±—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö —ç–∫–∑–µ–º–ø–ª—è—Ä–∞—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
/// –Ω–µ –≤–ª–∏—è–ª–∏ –Ω–∞ —Ç–µ–∫—É—â—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
private struct ContextOptimizationSettings {
    let maxContextLength: Int
    let maxRecentTurns: Int
    let enableEntityExtraction: Bool
    let enableVocabularyIntegration: Bool
    let postVADMergeThreshold: TimeInterval
    let baseContextPrompt: String

    /// –°–æ–∑–¥–∞–µ—Ç snapshot –∏–∑ —Ç–µ–∫—É—â–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    static func capture(from userSettings: UserSettingsProtocol) -> ContextOptimizationSettings {
        return ContextOptimizationSettings(
            maxContextLength: userSettings.maxContextLength,
            maxRecentTurns: userSettings.maxRecentTurns,
            enableEntityExtraction: userSettings.enableEntityExtraction,
            enableVocabularyIntegration: userSettings.enableVocabularyIntegration,
            postVADMergeThreshold: userSettings.postVADMergeThreshold,
            baseContextPrompt: userSettings.baseContextPrompt
        )
    }
}

/// –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ audio/video —Ñ–∞–π–ª–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å—Ç–µ—Ä–µ–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
///
/// `FileTranscriptionService` –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º
/// —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –¥–∏–∫—Ç–æ—Ä–æ–≤ –¥–ª—è —Å—Ç–µ—Ä–µ–æ –∑–∞–ø–∏—Å–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–≤–æ–Ω–∫–æ–≤). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç WhisperKit –¥–ª—è
/// on-device —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å Metal GPU acceleration.
///
/// ## –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
///
/// - **–°—Ç–µ—Ä–µ–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–≤—É—Ö –¥–∏–∫—Ç–æ—Ä–æ–≤ –ø–æ –∫–∞–Ω–∞–ª–∞–º (Left/Right)
/// - **Voice Activity Detection (VAD)**: –£–º–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ä–µ—á–µ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π —Ç–∏—à–∏–Ω—ã
/// - **–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è**: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–ø–ª–∏–∫–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏
/// - **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ**: –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–æ–≤—Ç–æ—Ä–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –æ–¥–Ω–∏—Ö –∏ —Ç–µ—Ö –∂–µ —Ñ–∞–π–ª–æ–≤
/// - **Real-time –ø—Ä–æ–≥—Ä–µ—Å—Å**: Callback –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
///
/// ## –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
///
/// MP3, M4A, WAV, AIFF, AAC, FLAC, MP4, MOV - –ª—é–±—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ AVFoundation
///
/// ## –†–µ–∂–∏–º—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
///
/// - **VAD —Ä–µ–∂–∏–º** (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è): –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Voice Activity Detection –¥–ª—è —É–º–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
/// - **Batch —Ä–µ–∂–∏–º**: –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —á–∞–Ω–∫–∞–º–∏ (–¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤)
///
/// ## –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
///
/// ```swift
/// // –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞
/// let whisperService = WhisperService(modelSize: "medium")
/// let audioCache = AudioCache()
/// let service = FileTranscriptionService(
///     whisperService: whisperService,
///     userSettings: UserSettings.shared,
///     audioCache: audioCache
/// )
///
/// // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
/// service.onProgressUpdate = { fileName, progress, partialDialogue in
///     print("Progress: \(Int(progress * 100))% - \(partialDialogue?.turns.count ?? 0) turns")
/// }
///
/// // –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å—Ç–µ—Ä–µ–æ —Ñ–∞–π–ª–∞
/// let dialogue = try await service.transcribeFileWithDialogue(at: audioURL)
/// print("Transcribed \(dialogue.turns.count) turns from \(dialogue.isStereo ? "stereo" : "mono") file")
///
/// // –î–æ—Å—Ç—É–ø –∫ —Ä–µ–ø–ª–∏–∫–∞–º
/// for turn in dialogue.sortedByTime {
///     print("[\(turn.startTime)s] \(turn.speaker.displayName): \(turn.text)")
/// }
/// ```
///
/// ## –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
///
/// - –°—Ç–µ—Ä–µ–æ —Ñ–∞–π–ª 60 –º–∏–Ω—É—Ç: ~10-15 –º–∏–Ω—É—Ç –Ω–∞ M1/M2 (model: medium, RTF ~0.2x)
/// - VAD —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è: ~0.5-2 —Å–µ–∫—É–Ω–¥—ã –Ω–∞ 60 –º–∏–Ω—É—Ç –∞—É–¥–∏–æ
/// - –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–Ω–∏–∂–∞–µ—Ç –ø–æ–≤—Ç–æ—Ä–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É —Å ~5s –¥–æ <0.1s
///
/// ## Thread Safety
///
/// –í—Å–µ –º–µ—Ç–æ–¥—ã –±–µ–∑–æ–ø–∞—Å–Ω—ã –¥–ª—è –≤—ã–∑–æ–≤–∞ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤. –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π AudioCache –∏—Å–ø–æ–ª—å–∑—É–µ—Ç actor –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏.
///
/// - Note: –î–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ SpectralVAD —Å preset `.telephone` –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
/// - Warning: –§–∞–π–ª—ã —Ä–∞–∑–º–µ—Ä–æ–º >500MB –º–æ–≥—É—Ç –≤—ã–∑–≤–∞—Ç—å –æ—à–∏–±–∫—É `TranscriptionError.fileTooLarge`
///
public class FileTranscriptionService {

    /// –†–µ–∂–∏–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Ñ–∞–π–ª–∞
    ///
    /// –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ –ø–µ—Ä–µ–¥ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π.
    public enum TranscriptionMode {
        /// Voice Activity Detection - —É–º–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ä–µ—á–µ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        ///
        /// –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç SpectralVAD –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        /// —Ç–∏—à–∏–Ω—ã –∏ —à—É–º–∞, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è —Ç–æ–ª—å–∫–æ —É—á–∞—Å—Ç–∫–∏ —Å —Ä–µ—á—å—é.
        case vad

        /// –ü–∞–∫–µ—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —á–∞–Ω–∫–∞–º–∏
        ///
        /// –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤. –î–µ–ª–∏—Ç –∞—É–¥–∏–æ –Ω–∞ —Ä–∞–≤–Ω—ã–µ —á–∞—Å—Ç–∏
        /// –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ.
        case batch
    }

    /// –ê–ª–≥–æ—Ä–∏—Ç–º Voice Activity Detection –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ä–µ—á–µ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    ///
    /// –î–æ—Å—Ç—É–ø–Ω—ã —Ç—Ä–∏ —Ç–∏–ø–∞ VAD –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ä–µ—á–∏:
    ///
    /// - **Standard**: –≠–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–π VAD –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–º–ø–ª–∏—Ç—É–¥—ã —Å–∏–≥–Ω–∞–ª–∞
    /// - **Adaptive**: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π VAD —Å Zero-Crossing Rate (ZCR) –∞–Ω–∞–ª–∏–∑–æ–º
    /// - **Spectral**: –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π VAD —Å FFT –∞–Ω–∞–ª–∏–∑–æ–º —á–∞—Å—Ç–æ—Ç (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
    ///
    /// ## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    ///
    /// - `.telephone` - –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π (300-3400 Hz)
    /// - `.wideband` - –¥–ª—è —à–∏—Ä–æ–∫–æ–ø–æ–ª–æ—Å–Ω–æ–≥–æ –∞—É–¥–∏–æ (80-8000 Hz)
    /// - `.default` - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π preset
    ///
    /// ## –ü—Ä–∏–º–µ—Ä
    ///
    /// ```swift
    /// service.vadAlgorithm = .telephone  // –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–≤–æ–Ω–∫–æ–≤
    /// ```
    public enum VADAlgorithm {
        /// –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–π VAD –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–º–ø–ª–∏—Ç—É–¥—ã
        case standard(VADParameters)

        /// –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π VAD —Å Zero-Crossing Rate –∞–Ω–∞–ª–∏–∑–æ–º
        case adaptive(AdaptiveVAD.Parameters)

        /// –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π VAD —Å FFT –∞–Ω–∞–ª–∏–∑–æ–º —á–∞—Å—Ç–æ—Ç (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
        case spectral(SpectralVAD.Parameters)

        /// Preset –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ (300-3400 Hz)
        ///
        /// –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —É–∑–∫–æ–ø–æ–ª–æ—Å–Ω—ã—Ö —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º
        /// —á–∞—Å—Ç–æ—Ç–Ω—ã–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º 300-3400 Hz.
        public static let telephone = VADAlgorithm.spectral(.telephone)

        /// Preset –¥–ª—è —à–∏—Ä–æ–∫–æ–ø–æ–ª–æ—Å–Ω–æ–≥–æ –∞—É–¥–∏–æ (80-8000 Hz)
        ///
        /// –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –∏ –∞—É–¥–∏–æ –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.
        public static let wideband = VADAlgorithm.spectral(.wideband)

        /// –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π preset –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
        public static let `default` = VADAlgorithm.spectral(.default)
    }

    /// –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ –¥–ª–∏–Ω–Ω—ã—Ö –∑–≤–æ–Ω–∫–∞—Ö
    private enum ContextOptimizationConstants {
        /// –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Ä–º–∏–Ω–æ–≤ —Å–ª–æ–≤–∞—Ä—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        static let maxVocabularyTermsInContext = 15

        /// –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ä–µ–ø–ª–∏–∫ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π
        static let maxRecentTurnsForEntityExtraction = 20
    }

    /// –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π
    /// (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ - –∫–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑)
    private static let entityExtractionRegex: NSRegularExpression? = {
        let englishPattern = "\\b[A-Z][a-z]+"
        let russianPattern = "\\b[–ê-–Ø–Å][–∞-—è—ë]+"
        let combinedPattern = "(\(englishPattern))|(\(russianPattern))"
        return try? NSRegularExpression(pattern: combinedPattern)
    }()

    private let whisperService: WhisperService
    private let userSettings: UserSettingsProtocol
    private var batchService: BatchTranscriptionService?
    private let audioCache: AudioCache

    /// –¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    ///
    /// –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `.vad` —Ä–µ–∂–∏–º —Å SpectralVAD –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.
    /// –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –≤–ª–∏—è–µ—Ç –Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ.
    ///
    /// - Note: –î–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ UserSettings –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `applyUserSettings()`
    public var mode: TranscriptionMode = .vad

    /// –ê–ª–≥–æ—Ä–∏—Ç–º Voice Activity Detection (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ .vad)
    ///
    /// –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `.telephone` preset (SpectralVAD —Å —á–∞—Å—Ç–æ—Ç–Ω—ã–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º 300-3400 Hz),
    /// –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π.
    ///
    /// ## –î–æ—Å—Ç—É–ø–Ω—ã–µ preset'—ã:
    /// - `.telephone` - –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–≤–æ–Ω–∫–æ–≤ (300-3400 Hz)
    /// - `.wideband` - –¥–ª—è —à–∏—Ä–æ–∫–æ–ø–æ–ª–æ—Å–Ω–æ–≥–æ –∞—É–¥–∏–æ (80-8000 Hz)
    /// - `.default` - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π
    ///
    /// - Note: –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è –≤ `.batch` —Ä–µ–∂–∏–º–µ
    public var vadAlgorithm: VADAlgorithm = .telephone

    /// Callback –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è real-time –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    ///
    /// –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ —Å –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º –∏ —á–∞—Å—Ç–∏—á–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º.
    ///
    /// ## –ü–∞—Ä–∞–º–µ—Ç—Ä—ã callback:
    /// - `fileName: String` - –∏–º—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º–æ–≥–æ —Ñ–∞–π–ª–∞
    /// - `progress: Double` - –ø—Ä–æ–≥—Ä–µ—Å—Å –æ—Ç 0.0 –¥–æ 1.0
    /// - `partialDialogue: DialogueTranscription?` - —á–∞—Å—Ç–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ —Ä–µ–ø–ª–∏–∫–∞–º–∏
    ///
    /// ## –ü—Ä–∏–º–µ—Ä:
    /// ```swift
    /// service.onProgressUpdate = { fileName, progress, dialogue in
    ///     DispatchQueue.main.async {
    ///         self.progressValue = progress
    ///         self.currentDialogue = dialogue
    ///     }
    /// }
    /// ```
    ///
    /// - Warning: Callback –º–æ–∂–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å—Å—è –∏–∑ —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `@MainActor` –∏–ª–∏ `DispatchQueue.main` –¥–ª—è UI –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π.
    public var onProgressUpdate: ((String, Double, DialogueTranscription?) -> Void)?

    /// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–µ—Ä–≤–∏—Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
    ///
    /// –ü–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ `userSettings` (—Ä–µ–∂–∏–º –∏ VAD –∞–ª–≥–æ—Ä–∏—Ç–º).
    ///
    /// - Parameters:
    ///   - whisperService: –°–µ—Ä–≤–∏—Å WhisperKit –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    ///   - userSettings: –ü—Ä–æ—Ç–æ–∫–æ–ª –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    ///   - audioCache: Actor –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö
    ///
    /// ## –ü—Ä–∏–º–µ—Ä:
    /// ```swift
    /// let service = FileTranscriptionService(
    ///     whisperService: WhisperService(modelSize: "medium"),
    ///     userSettings: UserSettings.shared,
    ///     audioCache: AudioCache()
    /// )
    /// ```
    public init(
        whisperService: WhisperService,
        userSettings: UserSettingsProtocol,
        audioCache: AudioCache
    ) {
        self.whisperService = whisperService
        self.userSettings = userSettings
        self.audioCache = audioCache
        self.batchService = BatchTranscriptionService(
            whisperService: whisperService,
            parameters: .lowQuality
        )
        // –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ UserSettings
        applyUserSettings()
    }

    /// –ü—Ä–∏–º–µ–Ω—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–µ–∂–∏–º–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏ VAD –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∏–∑ UserSettings
    ///
    /// –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Ä–≤–∏—Å–∞ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏:
    /// - –†–µ–∂–∏–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (VAD –∏–ª–∏ Batch)
    /// - VAD –∞–ª–≥–æ—Ä–∏—Ç–º –∏ –µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    ///
    /// –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏. –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –≤—ã–∑–æ–≤ –Ω–µ–æ–±—Ö–æ–¥–∏–º —Ç–æ–ª—å–∫–æ
    /// –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω—ã –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞.
    ///
    /// ## –ü—Ä–∏–º–µ—Ä:
    /// ```swift
    /// // –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏–∑–º–µ–Ω–∏–ª –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ UI
    /// UserSettings.shared.vadAlgorithmType = .spectralWideband
    ///
    /// // –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫ —Å–µ—Ä–≤–∏—Å—É
    /// service.applyUserSettings()
    /// ```
    ///
    /// - Note: –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤—Å—Ç—É–ø–∞—é—Ç –≤ —Å–∏–ª—É –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –≤—ã–∑–æ–≤–æ–≤ `transcribeFileWithDialogue()`
    public func applyUserSettings() {
        // –†–µ–∂–∏–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        switch userSettings.fileTranscriptionMode {
        case .vad:
            mode = .vad
        case .batch:
            mode = .batch
        }

        // VAD –∞–ª–≥–æ—Ä–∏—Ç–º
        switch userSettings.vadAlgorithmType {
        case .spectralTelephone:
            vadAlgorithm = .telephone
        case .spectralWideband:
            vadAlgorithm = .wideband
        case .spectralDefault:
            vadAlgorithm = .default
        case .adaptiveLowQuality:
            vadAlgorithm = .adaptive(AdaptiveVAD.Parameters.lowQuality)
        case .adaptiveAggressive:
            vadAlgorithm = .adaptive(AdaptiveVAD.Parameters.aggressive)
        case .standardLowQuality:
            vadAlgorithm = .standard(VADParameters.lowQuality)
        case .standardHighQuality:
            vadAlgorithm = .standard(VADParameters.highQuality)
        case .batch:
            // –î–ª—è batch —Ä–µ–∂–∏–º–∞ VAD –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π
            vadAlgorithm = .default
        }

        LogManager.app.info("FileTranscriptionService: –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ - —Ä–µ–∂–∏–º: \(self.mode == .vad ? "VAD" : "Batch"), –∞–ª–≥–æ—Ä–∏—Ç–º: \(self.vadAlgorithmName)")
    }

    // MARK: - Audio Cache Management

    /// –û—á–∏—â–∞–µ—Ç –∫—ç—à –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö
    ///
    /// –ü–æ–ª–µ–∑–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –ø–∞–º—è—Ç–∏.
    public func clearAudioCache() async {
        await audioCache.clearCache()
        LogManager.app.info("Audio cache cleared")
    }

    /// –£–¥–∞–ª—è–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª –∏–∑ –∫—ç—à–∞
    /// - Parameter url: URL —Ñ–∞–π–ª–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    public func evictFromCache(_ url: URL) async {
        await audioCache.evict(url)
        LogManager.app.debug("Evicted from cache: \(url.lastPathComponent)")
    }

    /// –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫—ç—à–∞
    /// - Returns: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π (hits, misses, hit rate)
    public func getCacheStatistics() async -> AudioCache.CacheStatistics {
        return await audioCache.getStatistics()
    }

    // MARK: - File Transcription

    /// –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –¥–∏–∫—Ç–æ—Ä–æ–≤ (–æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥)
    ///
    /// –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:
    /// - **–°—Ç–µ—Ä–µ–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–≤–∞ –¥–∏–∫—Ç–æ—Ä–∞ –ø–æ –∫–∞–Ω–∞–ª–∞–º (Left/Right)
    /// - **–ú–æ–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏**: –û–±—ã—á–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –¥–ª—è –æ–¥–Ω–æ–∫–∞–Ω–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    /// - **Real-time –ø—Ä–æ–≥—Ä–µ—Å—Å**: –û–±–Ω–æ–≤–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ `onProgressUpdate` callback
    /// - **–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è**: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–ø–ª–∏–∫–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏
    ///
    /// ## –ü—Ä–æ—Ü–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏:
    /// 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ Whisper –º–æ–¥–µ–ª–∏ (–æ–∂–∏–¥–∞–Ω–∏–µ –¥–æ 60 —Å–µ–∫—É–Ω–¥)
    /// 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–∞–Ω–∞–ª–æ–≤ (–º–æ–Ω–æ/—Å—Ç–µ—Ä–µ–æ)
    /// 3. VAD —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–ª–∏ batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç `mode`)
    /// 4. –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    /// 5. –í–æ–∑–≤—Ä–∞—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞
    ///
    /// ## –î–ª—è —Å—Ç–µ—Ä–µ–æ —Ñ–∞–π–ª–æ–≤:
    /// - Left channel ‚Üí Speaker 1 (blue)
    /// - Right channel ‚Üí Speaker 2 (orange)
    /// - –†–µ–ø–ª–∏–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ
    /// - –ö–∞–∂–¥–∞—è —Ä–µ–ø–ª–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
    ///
    /// ## –î–ª—è –º–æ–Ω–æ —Ñ–∞–π–ª–æ–≤:
    /// - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –æ–¥–∏–Ω Turn —Å –ø–æ–ª–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
    /// - Speaker = .left (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    ///
    /// - Parameter url: URL –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    /// - Returns: `DialogueTranscription` —Å–æ —Å–ø–∏—Å–∫–æ–º —Ä–µ–ø–ª–∏–∫, —Ñ–ª–∞–≥–æ–º —Å—Ç–µ—Ä–µ–æ –∏ –æ–±—â–µ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
    /// - Throws:
    ///   - `WhisperError.modelNotLoaded` - –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å –∑–∞ 60 —Å–µ–∫—É–Ω–¥
    ///   - `TranscriptionError.serviceNotInitialized` - BatchTranscriptionService –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
    ///   - `TranscriptionError.noAudioTrack` - —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∞—É–¥–∏–æ –¥–æ—Ä–æ–∂–∫–∏
    ///   - `TranscriptionError.audioLoadFailed` - –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ
    ///
    /// ## –ü—Ä–∏–º–µ—Ä:
    /// ```swift
    /// // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    /// service.onProgressUpdate = { fileName, progress, dialogue in
    ///     print("\(fileName): \(Int(progress * 100))%")
    ///     print("Processed turns: \(dialogue?.turns.count ?? 0)")
    /// }
    ///
    /// // –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
    /// let dialogue = try await service.transcribeFileWithDialogue(at: fileURL)
    ///
    /// // –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    /// if dialogue.isStereo {
    ///     print("Stereo dialogue with \(dialogue.turns.count) turns")
    ///     for turn in dialogue.sortedByTime {
    ///         print("[\(turn.startTime)s] \(turn.speaker.displayName): \(turn.text)")
    ///     }
    /// } else {
    ///     print("Mono transcription: \(dialogue.turns.first?.text ?? "")")
    /// }
    /// ```
    ///
    /// - Note: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ SpectralVAD —Å preset `.telephone` –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
    /// - Important: –ú–µ—Ç–æ–¥ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç AudioCache –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
    public func transcribeFileWithDialogue(at url: URL) async throws -> DialogueTranscription {
        LogManager.app.begin("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Ñ–∞–π–ª–∞ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –¥–∏–∫—Ç–æ—Ä–æ–≤: \(url.lastPathComponent)")

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–º–µ–Ω—É –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ
        try Task.checkCancellation()

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ Whisper
        if !whisperService.isReady {
            LogManager.app.error("–ú–æ–¥–µ–ª—å Whisper –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –æ–∂–∏–¥–∞–Ω–∏–µ...")
            // –ñ–¥—ë–º –¥–æ 60 —Å–µ–∫—É–Ω–¥ –ø–æ–∫–∞ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è
            for attempt in 1...60 {
                try await Task.sleep(nanoseconds: ServiceConstants.WaitIntervals.oneSecond)
                if whisperService.isReady {
                    LogManager.app.success("–ú–æ–¥–µ–ª—å Whisper –≥–æ—Ç–æ–≤–∞ (–ø–æ–ø—ã—Ç–∫–∞ \(attempt))")
                    break
                }
                if attempt == 60 {
                    LogManager.app.failure("–¢–∞–π–º–∞—É—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏", message: "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å –∑–∞ 60 —Å–µ–∫—É–Ω–¥")
                    throw WhisperError.modelNotLoaded
                }
            }
        }

        LogManager.app.info("–†–µ–∂–∏–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: \(self.mode == .batch ? "BATCH" : "VAD (\(self.vadAlgorithmName))")")

        // –ò—Å–ø–æ–ª—å–∑—É–µ–º batch —Ä–µ–∂–∏–º, –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω
        if mode == .batch {
            guard let batchService = batchService else {
                throw TranscriptionError.serviceNotInitialized("BatchTranscriptionService")
            }

            // –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º callback –≤ batchService
            batchService.onProgressUpdate = onProgressUpdate

            return try await batchService.transcribe(url: url)
        }

        // VAD —Ä–µ–∂–∏–º (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–¥)
        // 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—Ç–µ—Ä–µ–æ –ª–∏ —Ñ–∞–π–ª
        let channelCount = try await getChannelCount(from: url)
        LogManager.app.info("–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∫–∞–Ω–∞–ª–æ–≤: \(channelCount)")

        if channelCount == 2 {
            // –°—Ç–µ—Ä–µ–æ: —Ä–∞–∑–¥–µ–ª—è–µ–º –∫–∞–Ω–∞–ª—ã –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
            return try await transcribeStereoAsDialogue(url: url)
        } else {
            // –ú–æ–Ω–æ: –æ–±—ã—á–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
            let audioSamples = try await loadAudio(from: url)
            let totalDuration = TimeInterval(audioSamples.count) / 16000.0

            // –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
            let baseContextPrompt = self.userSettings.baseContextPrompt
            let contextPrompt = baseContextPrompt.isEmpty ? nil : baseContextPrompt
            let text = try await whisperService.transcribe(audioSamples: audioSamples, contextPrompt: contextPrompt)

            LogManager.app.info("–ú–æ–Ω–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: \(text.count) —Å–∏–º–≤–æ–ª–æ–≤")

            let dialogue = DialogueTranscription(
                turns: [DialogueTranscription.Turn(
                    speaker: .left,
                    text: text,
                    startTime: 0,
                    endTime: totalDuration
                )],
                isStereo: false,
                totalDuration: totalDuration
            )

            // –í—ã–∑—ã–≤–∞–µ–º callback –¥–ª—è –º–æ–Ω–æ —Ñ–∞–π–ª–æ–≤ —Ç–æ–∂–µ
            onProgressUpdate?(url.lastPathComponent, 1.0, dialogue)

            return dialogue
        }
    }

    /// –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∏–∫—Ç–æ—Ä–æ–≤ (–ø—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º)
    ///
    /// –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –±–µ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞.
    /// –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –º–æ–Ω–æ —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ –∫–æ–≥–¥–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∏–∫—Ç–æ—Ä–æ–≤.
    ///
    /// ## –ü—Ä–æ—Ü–µ—Å—Å:
    /// 1. –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ Whisper –º–æ–¥–µ–ª–∏ (–¥–æ 60 —Å–µ–∫—É–Ω–¥)
    /// 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ –≤ —Ñ–æ—Ä–º–∞—Ç WhisperKit (16kHz mono Float32)
    /// 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–∏—à–∏–Ω—É —Å –ø–æ–º–æ—â—å—é SilenceDetector
    /// 4. –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≤—Å–µ–≥–æ —Ñ–∞–π–ª–∞ –æ–¥–Ω–∏–º –±–ª–æ–∫–æ–º
    ///
    /// ## –û—Ç–ª–∏—á–∏—è –æ—Ç `transcribeFileWithDialogue()`:
    /// - ‚ùå –ù–µ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –¥–∏–∫—Ç–æ—Ä–æ–≤
    /// - ‚ùå –ù–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    /// - ‚ùå –ù–µ—Ç real-time –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    /// - ‚úÖ –ë—ã—Å—Ç—Ä–µ–µ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
    /// - ‚úÖ –ü—Ä–æ—â–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç (plain text)
    ///
    /// - Parameter url: URL –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    /// - Returns: –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    /// - Throws:
    ///   - `WhisperError.modelNotLoaded` - –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å –∑–∞ 60 —Å–µ–∫—É–Ω–¥
    ///   - `TranscriptionError.silenceDetected` - —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ç–∏—à–∏–Ω—É
    ///   - `TranscriptionError.emptyTranscription` - Whisper –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    ///   - `TranscriptionError.audioLoadFailed` - –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞
    ///
    /// ## –ü—Ä–∏–º–µ—Ä:
    /// ```swift
    /// // –ü—Ä–æ—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
    /// let text = try await service.transcribeFile(at: audioURL)
    /// print("Transcription: \(text)")
    /// ```
    ///
    /// - Warning: –î–ª—è —Å—Ç–µ—Ä–µ–æ —Ñ–∞–π–ª–æ–≤ –≤—Å–µ –∫–∞–Ω–∞–ª—ã –±—É–¥—É—Ç —Å–º–µ—à–∞–Ω—ã –≤ –º–æ–Ω–æ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `transcribeFileWithDialogue()` –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∏–∫—Ç–æ—Ä–æ–≤.
    /// - Note: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `transcribeFileWithDialogue()` –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
    public func transcribeFile(at url: URL) async throws -> String {
        LogManager.app.begin("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Ñ–∞–π–ª–∞: \(url.lastPathComponent)")

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ Whisper
        if !whisperService.isReady {
            LogManager.app.error("–ú–æ–¥–µ–ª—å Whisper –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –æ–∂–∏–¥–∞–Ω–∏–µ...")
            // –ñ–¥—ë–º –¥–æ 60 —Å–µ–∫—É–Ω–¥ –ø–æ–∫–∞ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è
            for attempt in 1...60 {
                try await Task.sleep(nanoseconds: ServiceConstants.WaitIntervals.oneSecond)
                if whisperService.isReady {
                    LogManager.app.success("–ú–æ–¥–µ–ª—å Whisper –≥–æ—Ç–æ–≤–∞ (–ø–æ–ø—ã—Ç–∫–∞ \(attempt))")
                    break
                }
                if attempt == 60 {
                    LogManager.app.failure("–¢–∞–π–º–∞—É—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏", message: "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å –∑–∞ 60 —Å–µ–∫—É–Ω–¥")
                    throw WhisperError.modelNotLoaded
                }
            }
        }

        // 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ –∏–∑ —Ñ–∞–π–ª–∞
        let audioSamples = try await loadAudio(from: url)

        // 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ç–∏—à–∏–Ω—É
        if SilenceDetector.shared.isSilence(audioSamples) {
            LogManager.app.info("üîá –§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ç–∏—à–∏–Ω—É")
            throw TranscriptionError.silenceDetected(url)
        }

        // 3. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
        let transcription = try await whisperService.transcribe(audioSamples: audioSamples)

        if transcription.isEmpty {
            throw TranscriptionError.emptyTranscription(url)
        }

        LogManager.app.success("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Ñ–∞–π–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: \(transcription.count) —Å–∏–º–≤–æ–ª–æ–≤")
        return transcription
    }

    /// –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—É–¥–∏–æ –∏–∑ —Ñ–∞–π–ª–∞ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç WhisperKit (16kHz mono Float32)
    /// - Parameter url: URL —Ñ–∞–π–ª–∞
    /// - Returns: –ú–∞—Å—Å–∏–≤ audio samples
    /// - Throws: –û—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
    private func loadAudio(from url: URL) async throws -> [Float] {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º AudioCache –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        let cachedAudio = try await audioCache.loadAudio(from: url)

        let isCached = await audioCache.isCached(url)
        if isCached {
            LogManager.app.debug("–ê—É–¥–∏–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ –∫—ç—à–∞: \(url.lastPathComponent)")
        } else {
            let durationSeconds = Float(cachedAudio.monoSamples.count) / 16000.0
            LogManager.app.success("–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: \(cachedAudio.monoSamples.count) samples, \(String(format: "%.1f", durationSeconds))s")
        }

        return cachedAudio.monoSamples
    }

    /// –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—É–¥–∏–æ –∫–∞–Ω–∞–ª–æ–≤ –≤ —Ñ–∞–π–ª–µ
    private func getChannelCount(from url: URL) async throws -> Int {
        let asset = AVAsset(url: url)
        guard let audioTrack = try await asset.loadTracks(withMediaType: .audio).first else {
            throw TranscriptionError.noAudioTrack(url)
        }

        let formatDescriptions = try await audioTrack.load(.formatDescriptions)
        guard let formatDescription = formatDescriptions.first else {
            return 1 // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –º–æ–Ω–æ
        }

        if let audioStreamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription) {
            return Int(audioStreamBasicDescription.pointee.mChannelsPerFrame)
        }

        return 1
    }

    /// –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞ —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –∫–∞–Ω–∞–ª—É
    private struct ChannelSegment {
        let segment: SpeechSegment
        let channel: Int  // 0 = left, 1 = right
        let speaker: DialogueTranscription.Turn.Speaker
        let audioSamples: [Float]
    }

    /// –°–ª–∏–≤–∞–µ—Ç —Å–æ—Å–µ–¥–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –æ–¥–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞ —Å –∫–æ—Ä–æ—Ç–∫–∏–º –ø—Ä–æ–º–µ–∂—É—Ç–∫–æ–º
    /// - Parameters:
    ///   - segments: –ú–∞—Å—Å–∏–≤ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–ª–∏—è–Ω–∏—è (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –≤—Ä–µ–º–µ–Ω–∏)
    ///   - maxGap: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–µ–∂—É—Ç–æ–∫ –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è —Å–ª–∏—è–Ω–∏—è (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
    /// - Returns: –ú–∞—Å—Å–∏–≤ —Å–ª–∏—Ç—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    private func mergeAdjacentSegments(_ segments: [ChannelSegment], maxGap: TimeInterval) -> [ChannelSegment] {
        guard segments.count > 1 else { return segments }

        var merged: [ChannelSegment] = []
        var currentSegment = segments[0]

        for i in 1..<segments.count {
            let nextSegment = segments[i]

            // –ü—Ä–æ–≤–µ—Ä–∫–∞: —Ç–æ—Ç –∂–µ —Å–ø–∏–∫–µ—Ä –∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ–∫ < maxGap
            let gap = nextSegment.segment.startTime - currentSegment.segment.endTime
            if currentSegment.speaker == nextSegment.speaker && gap < maxGap {
                // –°–ª–∏—è–Ω–∏–µ: –æ–±—ä–µ–¥–∏–Ω—è–µ–º –∞—É–¥–∏–æ –∏ —Ä–∞—Å—à–∏—Ä—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏
                let mergedAudio = currentSegment.audioSamples + nextSegment.audioSamples
                currentSegment = ChannelSegment(
                    segment: SpeechSegment(
                        startTime: currentSegment.segment.startTime,
                        endTime: nextSegment.segment.endTime
                    ),
                    channel: currentSegment.channel,
                    speaker: currentSegment.speaker,
                    audioSamples: mergedAudio
                )
            } else {
                // –†–∞–∑–Ω—ã–µ —Å–ø–∏–∫–µ—Ä—ã –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –ø—Ä–æ–º–µ–∂—É—Ç–æ–∫ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π
                merged.append(currentSegment)
                currentSegment = nextSegment
            }
        }
        merged.append(currentSegment) // –ù–µ –∑–∞–±—ã—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç

        return merged
    }

    /// –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç —Å—Ç–µ—Ä–µ–æ —Ñ–∞–π–ª –∫–∞–∫ –¥–∏–∞–ª–æ–≥ (–ª–µ–≤—ã–π –∏ –ø—Ä–∞–≤—ã–π –∫–∞–Ω–∞–ª—ã –æ—Ç–¥–µ–ª—å–Ω–æ)
    /// –£–õ–£–ß–®–ï–ù–ù–´–ô –ê–õ–ì–û–†–ò–¢–ú: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –≤ —à–∞—Ö–º–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏,
    /// –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥—ã–¥—É—â–∏–π –¥–∏–∞–ª–æ–≥ –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
    private func transcribeStereoAsDialogue(url: URL) async throws -> DialogueTranscription {
        LogManager.app.info("üéß –°—Ç–µ—Ä–µ–æ —Ä–µ–∂–∏–º: —Ä–∞–∑–¥–µ–ª—è–µ–º –∫–∞–Ω–∞–ª—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∏–∫—Ç–æ—Ä–æ–≤")

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–º–µ–Ω—É –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
        try Task.checkCancellation()

        // 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞: –∑–∞–≥—Ä—É–∑–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–µ—Ä–µ–æ –∫–∞–Ω–∞–ª–æ–≤
        let (leftChannel, rightChannel, totalDuration) = try await prepareStereoChanels(from: url)

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–º–µ–Ω—É –ø–µ—Ä–µ–¥ VAD –∞–Ω–∞–ª–∏–∑–æ–º
        try Task.checkCancellation()

        // 2. VAD –∞–Ω–∞–ª–∏–∑: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Ä–µ—á–∏
        let allSegments = try await detectAndMergeStereoSegments(
            left: leftChannel,
            right: rightChannel
        )

        // 3. –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è: –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ
        let turns = try await transcribeSegmentsInOrder(
            allSegments,
            fileName: url.lastPathComponent,
            totalDuration: totalDuration
        )

        LogManager.app.success("–°—Ç–µ—Ä–µ–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: \(turns.count) —Ä–µ–ø–ª–∏–∫ (–æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ)")

        return DialogueTranscription(turns: turns, isStereo: true, totalDuration: totalDuration)
    }

    /// –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç–µ—Ä–µ–æ –∫–∞–Ω–∞–ª–æ–≤: –∑–∞–≥—Ä—É–∑–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∞—É–¥–∏–æ
    /// - Parameter url: URL –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
    /// - Returns: –ö–æ—Ä—Ç–µ–∂ –∏–∑ –ª–µ–≤–æ–≥–æ –∫–∞–Ω–∞–ª–∞, –ø—Ä–∞–≤–æ–≥–æ –∫–∞–Ω–∞–ª–∞ –∏ –æ–±—â–µ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    private func prepareStereoChanels(from url: URL) async throws -> (left: [Float], right: [Float], duration: TimeInterval) {
        // –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–µ—Ä–µ–æ –∞—É–¥–∏–æ
        let stereoSamples = try await loadAudioStereo(from: url)

        // –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –ª–µ–≤—ã–π –∏ –ø—Ä–∞–≤—ã–π –∫–∞–Ω–∞–ª—ã
        let leftChannel = extractChannel(from: stereoSamples, channel: 0)
        let rightChannel = extractChannel(from: stereoSamples, channel: 1)

        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (16kHz sample rate)
        let totalDuration = TimeInterval(leftChannel.count) / 16000.0

        return (leftChannel, rightChannel, totalDuration)
    }

    /// –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ—á–µ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ –æ–±–æ–∏—Ö —Å—Ç–µ—Ä–µ–æ –∫–∞–Ω–∞–ª–æ–≤
    /// - Parameters:
    ///   - left: –õ–µ–≤—ã–π –∞—É–¥–∏–æ –∫–∞–Ω–∞–ª
    ///   - right: –ü—Ä–∞–≤—ã–π –∞—É–¥–∏–æ –∫–∞–Ω–∞–ª
    /// - Returns: –ú–∞—Å—Å–∏–≤ —Å–µ–≥–º–µ–Ω—Ç–æ–≤, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    private func detectAndMergeStereoSegments(
        left: [Float],
        right: [Float]
    ) async throws -> [ChannelSegment] {
        // VAD –∞–Ω–∞–ª–∏–∑ –ª–µ–≤–æ–≥–æ –∫–∞–Ω–∞–ª–∞
        LogManager.app.info("üé§ VAD: –∞–Ω–∞–ª–∏–∑ –ª–µ–≤–æ–≥–æ –∫–∞–Ω–∞–ª–∞ (–∞–ª–≥–æ—Ä–∏—Ç–º: \(self.vadAlgorithmName))...")
        let leftSegments = detectSegments(in: left)
        LogManager.app.info("–ù–∞–π–¥–µ–Ω–æ \(leftSegments.count) —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Ä–µ—á–∏ –≤ –ª–µ–≤–æ–º –∫–∞–Ω–∞–ª–µ")

        // VAD –∞–Ω–∞–ª–∏–∑ –ø—Ä–∞–≤–æ–≥–æ –∫–∞–Ω–∞–ª–∞
        LogManager.app.info("üé§ VAD: –∞–Ω–∞–ª–∏–∑ –ø—Ä–∞–≤–æ–≥–æ –∫–∞–Ω–∞–ª–∞ (–∞–ª–≥–æ—Ä–∏—Ç–º: \(self.vadAlgorithmName))...")
        let rightSegments = detectSegments(in: right)
        LogManager.app.info("–ù–∞–π–¥–µ–Ω–æ \(rightSegments.count) —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Ä–µ—á–∏ –≤ –ø—Ä–∞–≤–æ–º –∫–∞–Ω–∞–ª–µ")

        // –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –∏–∑ –æ–±–æ–∏—Ö –∫–∞–Ω–∞–ª–æ–≤
        var allSegments: [ChannelSegment] = []

        // –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        for segment in leftSegments {
            let audio = extractSegmentAudio(segment, from: left)
            allSegments.append(ChannelSegment(
                segment: segment,
                channel: 0,
                speaker: DialogueTranscription.Turn.Speaker.left,
                audioSamples: audio
            ))
        }

        // –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∞–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        for segment in rightSegments {
            let audio = extractSegmentAudio(segment, from: right)
            allSegments.append(ChannelSegment(
                segment: segment,
                channel: 1,
                speaker: DialogueTranscription.Turn.Speaker.right,
                audioSamples: audio
            ))
        }

        // –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        allSegments.sort(by: { $0.segment.startTime < $1.segment.startTime })
        LogManager.app.info("üîÑ –°–µ–≥–º–µ–Ω—Ç—ã –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (\(allSegments.count) –≤—Å–µ–≥–æ)")

        // Post-VAD merge: —Å–ª–∏–≤–∞–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –æ–¥–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞ —Å –∫–æ—Ä–æ—Ç–∫–∏–º –ø—Ä–æ–º–µ–∂—É—Ç–∫–æ–º
        let segmentCountBefore = allSegments.count
        allSegments = mergeAdjacentSegments(allSegments, maxGap: self.userSettings.postVADMergeThreshold)
        let segmentCountAfter = allSegments.count
        if segmentCountBefore != segmentCountAfter {
            LogManager.app.info("üîó Post-VAD merge: \(segmentCountBefore) ‚Üí \(segmentCountAfter) —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (–ø–æ—Ä–æ–≥: \(String(format: "%.1f", self.userSettings.postVADMergeThreshold))—Å)")
        }

        return allSegments
    }

    /// –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    /// - Parameters:
    ///   - segments: –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∞—Å—Å–∏–≤ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    ///   - fileName: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    ///   - totalDuration: –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    /// - Returns: –ú–∞—Å—Å–∏–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ä–µ–ø–ª–∏–∫ –¥–∏–∞–ª–æ–≥–∞
    private func transcribeSegmentsInOrder(
        _ segments: [ChannelSegment],
        fileName: String,
        totalDuration: TimeInterval
    ) async throws -> [DialogueTranscription.Turn] {
        var turns: [DialogueTranscription.Turn] = []
        let totalSegments = segments.count
        var processedSegments = 0

        for channelSegment in segments {
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–º–µ–Ω—É –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
            try Task.checkCancellation()

            let segment = channelSegment.segment
            let speaker = channelSegment.speaker
            let segmentAudio = channelSegment.audioSamples

            // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã —Å —Ç–∏—à–∏–Ω–æ–π
            if SilenceDetector.shared.isSilence(segmentAudio) {
                continue
            }

            // –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N —Ä–µ–ø–ª–∏–∫ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É)
            let contextPrompt = buildContextPrompt(from: turns)

            let speakerName = speaker == .left ? "Speaker 1" : "Speaker 2"
            LogManager.app.info("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º \(speakerName): \(String(format: "%.1f", segment.startTime))s - \(String(format: "%.1f", segment.endTime))s (–∫–æ–Ω—Ç–µ–∫—Å—Ç: \(contextPrompt.isEmpty ? "–Ω–µ—Ç" : "\(contextPrompt.count) —Å–∏–º–≤–æ–ª–æ–≤"))")

            // –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            let text = try await whisperService.transcribe(
                audioSamples: segmentAudio,
                contextPrompt: contextPrompt.isEmpty ? nil : contextPrompt
            )

            if !text.isEmpty {
                turns.append(DialogueTranscription.Turn(
                    speaker: speaker,
                    text: text,
                    startTime: segment.startTime,
                    endTime: segment.endTime
                ))

                // –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —Ä–µ–ø–ª–∏–∫–∏
                processedSegments += 1
                let progress = Double(processedSegments) / Double(totalSegments)
                let partialDialogue = DialogueTranscription(turns: turns, isStereo: true, totalDuration: totalDuration)
                LogManager.app.debug("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: \(processedSegments)/\(totalSegments), turns: \(turns.count)")
                onProgressUpdate?(fileName, progress, partialDialogue)
            } else {
                LogManager.app.warning("\(speakerName): –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞ \(String(format: "%.1f", segment.startTime))s")
            }
        }

        return turns
    }

    /// –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ (–∏–º–µ–Ω–∞, –∫–æ–º–ø–∞–Ω–∏–∏) –∏–∑ —Ä–µ–ø–ª–∏–∫ –¥–∏–∞–ª–æ–≥–∞
    /// - Parameter turns: –ú–∞—Å—Å–∏–≤ —Ä–µ–ø–ª–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    /// - Returns: –ú–∞—Å—Å–∏–≤ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π
    private func extractNamedEntities(from turns: [DialogueTranscription.Turn]) -> [String] {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        guard let regex = Self.entityExtractionRegex else {
            LogManager.app.warning("Entity extraction regex –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return []
        }

        // –°—Ç–æ–ø-—Å–ª–æ–≤–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–æ–±—â–∏–µ —Å–ª–æ–≤–∞ –≤ –Ω–∞—á–∞–ª–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)
        let stopWords: Set<String> = [
            "The", "And", "Or", "But", "If", "When", "Where", "Who", "What", "Why", "How",
            "Speaker", "Yes", "No", "Ok", "Okay", "Well", "So", "Then", "Now", "Here", "There",
            "This", "That", "These", "Those", "He", "She", "It", "They", "We", "You", "I"
        ]

        var entities = Set<String>()

        // –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—â–Ω–æ—Å—Ç–∏ —Ç–æ–ª—å–∫–æ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N —Ä–µ–ø–ª–∏–∫ (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏)
        let recentTurnsForEntities = Array(turns.suffix(ContextOptimizationConstants.maxRecentTurnsForEntityExtraction))

        for turn in recentTurnsForEntities {
            let text = turn.text
            let range = NSRange(text.startIndex..., in: text)
            let matches = regex.matches(in: text, range: range)

            for match in matches {
                if let matchRange = Range(match.range, in: text) {
                    let entity = String(text[matchRange])
                    // –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
                    if !stopWords.contains(entity) {
                        entities.insert(entity)
                    }
                }
            }
        }

        return Array(entities).sorted() // –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∞—Å—Å–∏–≤
    }

    /// –ù–û–í–û–ï: –§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–µ–ø–ª–∏–∫ –¥–∏–∞–ª–æ–≥–∞
    /// –ü–æ–º–æ–≥–∞–µ—Ç Whisper –ª—É—á—à–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –∏–º–µ–Ω–∞, —Ç–µ—Ä–º–∏–Ω—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
    private func buildContextPrompt(from turns: [DialogueTranscription.Turn], maxTurns: Int? = nil) -> String {
        var contextParts: [String] = []
        var debugStats = (base: 0, entities: 0, vocab: 0, turns: 0)

        // –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        let baseContextPrompt = self.userSettings.baseContextPrompt
        if !baseContextPrompt.isEmpty {
            contextParts.append(baseContextPrompt)
            debugStats.base = baseContextPrompt.count
        }

        // –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        if self.userSettings.enableEntityExtraction && !turns.isEmpty {
            let entities = extractNamedEntities(from: turns)
            if !entities.isEmpty {
                let entitiesContext = "Named entities: " + entities.joined(separator: ", ")
                contextParts.append(entitiesContext)
                debugStats.entities = entities.count
            }
        }

        // –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Å–ª–æ–≤–∞—Ä—è –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        var vocabularyTermsCount = 0
        if self.userSettings.enableVocabularyIntegration {
            let vocabularyWords = self.userSettings.getEnabledVocabularyWords()
            if !vocabularyWords.isEmpty {
                // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Å—Ç–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                let limitedWords = Array(vocabularyWords.prefix(ContextOptimizationConstants.maxVocabularyTermsInContext))
                let vocabularyContext = "Vocabulary: " + limitedWords.joined(separator: ", ")
                contextParts.append(vocabularyContext)
                vocabularyTermsCount = limitedWords.count
                debugStats.vocab = vocabularyTermsCount
            }
        }

        // –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Ä–µ–ø–ª–∏–∫ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É –∏–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
        let turnsToTake = maxTurns ?? self.userSettings.maxRecentTurns
        let recentTurns = Array(turns.suffix(turnsToTake))

        if !recentTurns.isEmpty {
            // –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –≤–∏–¥–µ –¥–∏–∞–ª–æ–≥–∞
            let dialogueContext = recentTurns.map { turn in
                let speakerName = turn.speaker == .left ? "Speaker 1" : "Speaker 2"
                return "\(speakerName): \(turn.text)"
            }.joined(separator: " ")
            contextParts.append(dialogueContext)
            debugStats.turns = recentTurns.count
        }

        // –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞—Å—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        let fullContext = contextParts.joined(separator: ". ")

        // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É—è –Ω–∞—Å—Ç—Ä–æ–π–∫—É maxContextLength
        let maxLength = self.userSettings.maxContextLength
        if fullContext.count > maxLength {
            // –£–º–Ω–æ–µ —É—Å–µ—á–µ–Ω–∏–µ –ø–æ –≥—Ä–∞–Ω–∏—Ü–µ —Å–ª–æ–≤–∞ —Å Unicode-–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é
            guard let targetIndex = fullContext.index(fullContext.startIndex, offsetBy: maxLength, limitedBy: fullContext.endIndex) else {
                // Edge case: maxLength –±–æ–ª—å—à–µ –¥–ª–∏–Ω—ã —Å—Ç—Ä–æ–∫–∏ (–Ω–µ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å, –Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)
                return fullContext
            }

            let searchRange = fullContext.startIndex..<targetIndex

            // –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –ª–∏–º–∏—Ç–æ–º
            if let lastSpaceRange = fullContext.range(of: " ", options: .backwards, range: searchRange) {
                // –û–±—Ä–µ–∑–∞–µ–º –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –ø—Ä–æ–±–µ–ª—É
                let truncated = String(fullContext[..<lastSpaceRange.lowerBound])
                let finalLength = truncated.count
                LogManager.transcription.debug("Context truncated: base=\(debugStats.base)ch, entities=\(debugStats.entities), vocab=\(debugStats.vocab), turns=\(debugStats.turns), \(fullContext.count)ch ‚Üí \(finalLength)ch")
                return truncated + "..."
            } else {
                // Edge case: –Ω–µ—Ç –ø—Ä–æ–±–µ–ª–æ–≤ - –æ–±—Ä–µ–∑–∞–µ–º –ø–æ –ª–∏–º–∏—Ç—É —Å Unicode-–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é
                // limitedBy –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –Ω–µ –æ–±—Ä–µ–∂–µ–º –ø–æ—Å—Ä–µ–¥–∏ grapheme cluster (emoji, –¥–∏–∞–∫—Ä–∏—Ç–∏–∫–∏)
                let safeIndex = fullContext.index(fullContext.startIndex, offsetBy: maxLength, limitedBy: fullContext.endIndex) ?? fullContext.endIndex
                let truncated = String(fullContext[..<safeIndex])
                LogManager.transcription.debug("Context truncated (no spaces): base=\(debugStats.base)ch, entities=\(debugStats.entities), vocab=\(debugStats.vocab), turns=\(debugStats.turns), \(fullContext.count)ch ‚Üí \(truncated.count)ch")
                return truncated + "..."
            }
        }

        // –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        LogManager.transcription.debug("Context built: base=\(debugStats.base)ch, entities=\(debugStats.entities), vocab=\(debugStats.vocab), turns=\(debugStats.turns), final=\(fullContext.count)ch")

        return fullContext
    }

    /// –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç–µ—Ä–µ–æ –∞—É–¥–∏–æ (—Å–æ—Ö—Ä–∞–Ω—è—è –æ–±–∞ –∫–∞–Ω–∞–ª–∞)
    private func loadAudioStereo(from url: URL) async throws -> [[Float]] {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º AudioCache –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        let cachedAudio = try await audioCache.loadAudio(from: url)

        let isCached = await audioCache.isCached(url)
        if isCached {
            LogManager.app.debug("–°—Ç–µ—Ä–µ–æ –∞—É–¥–∏–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ –∫—ç—à–∞: \(url.lastPathComponent)")
        }

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ stereo
        guard cachedAudio.isStereo, let stereoChannels = cachedAudio.stereoChannels else {
            throw TranscriptionError.notStereoFile(url)
        }

        // –í–æ–∑–≤—Ä–∞—â–∞–µ–º interleaved —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º
        // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º (left, right) –æ–±—Ä–∞—Ç–Ω–æ –≤ interleaved [L, R, L, R, ...]
        var interleavedSamples: [Float] = []
        interleavedSamples.reserveCapacity(stereoChannels.left.count * 2)

        for i in 0..<stereoChannels.left.count {
            interleavedSamples.append(stereoChannels.left[i])
            if i < stereoChannels.right.count {
                interleavedSamples.append(stereoChannels.right[i])
            }
        }

        return [interleavedSamples]
    }

    /// –ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–¥–∏–Ω –∫–∞–Ω–∞–ª –∏–∑ interleaved —Å—Ç–µ—Ä–µ–æ
    private func extractChannel(from stereoData: [[Float]], channel: Int) -> [Float] {
        guard let interleavedSamples = stereoData.first else { return [] }

        var channelSamples: [Float] = []
        channelSamples.reserveCapacity(interleavedSamples.count / 2)

        // Interleaved format: L, R, L, R, L, R, ...
        // channel 0 = left (indices 0, 2, 4, ...)
        // channel 1 = right (indices 1, 3, 5, ...)
        stride(from: channel, to: interleavedSamples.count, by: 2).forEach { index in
            channelSamples.append(interleavedSamples[index])
        }

        let durationSeconds = Float(channelSamples.count) / 16000.0
        LogManager.app.info("–ö–∞–Ω–∞–ª \(channel): \(channelSamples.count) samples, \(String(format: "%.1f", durationSeconds))s")

        return channelSamples
    }

    // MARK: - VAD Helpers

    /// –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã —Ä–µ—á–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞
    private func detectSegments(in samples: [Float]) -> [SpeechSegment] {
        switch vadAlgorithm {
        case .standard(let params):
            let vad = VoiceActivityDetector(parameters: params)
            return vad.detectSpeechSegments(in: samples)

        case .adaptive(let params):
            let vad = AdaptiveVAD(parameters: params)
            return vad.detectSpeechSegments(in: samples)

        case .spectral(let params):
            let vad = SpectralVAD(parameters: params)
            return vad.detectSpeechSegments(in: samples)
        }
    }

    /// –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞
    private func extractSegmentAudio(_ segment: SpeechSegment, from samples: [Float]) -> [Float] {
        let startIndex = max(0, segment.startSample)
        let endIndex = min(samples.count, segment.endSample)

        guard startIndex < endIndex && startIndex < samples.count else {
            return []
        }

        return Array(samples[startIndex..<endIndex])
    }

    /// –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ VAD –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    private var vadAlgorithmName: String {
        switch vadAlgorithm {
        case .standard:
            return "Standard VAD"
        case .adaptive:
            return "Adaptive VAD"
        case .spectral(let params):
            if params.speechFreqMin == 300 && params.speechFreqMax == 3400 {
                return "Spectral VAD (Telephone)"
            } else if params.speechFreqMin == 80 && params.speechFreqMax == 8000 {
                return "Spectral VAD (Wideband)"
            } else {
                return "Spectral VAD"
            }
        }
    }

}
